{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31e1db3-07fa-4bcf-b59c-6f0048578292",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.linalg import svd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#Understand and visualize data\n",
    "# ------------------- PARAMETERS -------------------\n",
    "file_path = '/home/jsadiq/Downloads/Shafqat/merged_rom.txt'#'reduced_order_method.txt'\n",
    "num_timesteps = 40001\n",
    "num_points = 9\n",
    "num_velocities = 201\n",
    "num_modes = 5\n",
    "data = np.loadtxt(file_path)\n",
    "expected_size = num_timesteps * num_points * num_velocities\n",
    "if data.size != expected_size:\n",
    "    raise ValueError(f\"Data size {data.size} does not match expected size {expected_size}\")\n",
    "data = data.reshape((num_timesteps, num_points, num_velocities))\n",
    "time_interval = 0.002\n",
    "time_values = np.linspace(0, (num_timesteps - 1) * time_interval, num_timesteps)\n",
    "#use all data to train not fixed ones \n",
    "velocities_to_plot = np.linspace(100, 500, 50)#num_velocities) #[100, 140, 180, 220, 260, 300, 340, 380, 420, 460, 500]\n",
    "velocity_values = np.linspace(100, 500, 50)#num_velocities)\n",
    "num_modes = 5\n",
    "\n",
    "# POD-based ROM computation\n",
    "num_timesteps, num_points, num_velocities = data.shape\n",
    "pod_solutions = {} # collect the reconstructed reduced solution at each time step for each velocity\n",
    "                       # Each key is a velocity, and each value is a list of reduced solutions over time\n",
    "pod_bases = {}\n",
    "pod_coefficients = {}\n",
    "\n",
    "# Map velocity value to index in the data\n",
    "velocity_to_index = {v: i for i, v in enumerate(velocity_values)}\n",
    "for timestep in range(num_timesteps):\n",
    "    snapshot_matrix = data[timestep, :, :]  # Shape: (num_points, num_velocities)\n",
    "    # POD = SVD of the snapshot matrix\n",
    "    Phi, singular_values, VT = svd(snapshot_matrix, full_matrices=False)\n",
    "\n",
    "    # Truncate to first `num_modes` POD modes (can also be selected automatically or we give a value)\n",
    "    pod_basis = Phi[:, :num_modes]                       # Spatial POD modes (basis) left singular matrix\n",
    "    Sigma_r = np.diag(singular_values[:num_modes])       # Energy (singular values) \n",
    "    temporal_modes = VT[:num_modes, :]                   # Temporal/parametric info also right singular matrix\n",
    "\n",
    "    for velocity in velocities_to_plot:\n",
    "        if velocity not in velocity_to_index:\n",
    "            raise ValueError(f\"Velocity {velocity} not found in velocity_values.\")\n",
    "        v_idx = velocity_to_index[velocity]\n",
    "\n",
    "        # Compute modal coefficients α = Σ_r × VT_r[:, v_idx]\n",
    "        alpha = Sigma_r @ temporal_modes[:, v_idx]  # Shape: (num_modes,)\n",
    "        reduced_solution = pod_basis @ alpha        # Linear combination: Φ × α, here I want alpha to be trained\n",
    "\n",
    "        pod_solutions.setdefault(velocity, []).append(reduced_solution) # for time series data\n",
    "\n",
    "        # Save basis and coefficients from the first timestep only\n",
    "        if timestep == 0:\n",
    "            pod_bases[velocity] = pod_basis\n",
    "            pod_coefficients.setdefault(velocity, []).append(alpha)\n",
    "        else:\n",
    "            pod_coefficients[velocity].append(alpha)\n",
    "\n",
    "# Convert all lists to arrays\n",
    "for v in pod_solutions:\n",
    "    pod_solutions[v] = np.array(pod_solutions[v])\n",
    "    pod_coefficients[v] = np.array(pod_coefficients[v])\n",
    "\n",
    "for velocity, solution in pod_solutions.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(time_values, solution[:, 0], label=f'POD @ {velocity} m/s', linewidth=1.5)\n",
    "    plt.title(f'POD Reduced Solution at {velocity} m/s')\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Displacement [cm]\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    #file_path = os.path.join(output_folder, f\"pod_solution_{velocity}.png\")\n",
    "    #plt.savefig(file_path)\n",
    "    plt.show()\n",
    "    #print(f\"POD plots saved to folder: {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c612a9db-bd6a-4907-8b76-7fe705e2bdcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18c62b0-4901-4248-a2f0-5933ddb86c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.linalg import svd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "def load_and_reshape_data(file_path, num_timesteps, num_points, num_velocities):\n",
    "    data = np.loadtxt(file_path)\n",
    "    expected_size = num_timesteps * num_points * num_velocities\n",
    "    if data.size != expected_size:\n",
    "        raise ValueError(f\"Data size {data.size} does not match expected size {expected_size}\")\n",
    "    return data.reshape((num_timesteps, num_points, num_velocities))\n",
    "\n",
    "# POD-based ROM computation\n",
    "def compute_pod_solutions(data, velocities_to_plot, velocity_values, num_modes):\n",
    "    \"\"\"\n",
    "    Apply POD and reconstruct solutions for selected velocities using reduced basis.\n",
    "    \"\"\"\n",
    "    num_timesteps, num_points, num_velocities = data.shape\n",
    "    pod_solutions = {} # collect the reconstructed reduced solution at each time step for each velocity\n",
    "                       # Each key is a velocity, and each value is a list of reduced solutions over time\n",
    "    pod_bases = {}\n",
    "    pod_coefficients = {}\n",
    "\n",
    "    # Map velocity value to index in the data\n",
    "    velocity_to_index = {v: i for i, v in enumerate(velocity_values)}\n",
    "\n",
    "    for timestep in range(num_timesteps):\n",
    "        snapshot_matrix = data[timestep, :, :]  # Shape: (num_points, num_velocities)\n",
    "\n",
    "        # POD = SVD of the snapshot matrix\n",
    "        Phi, singular_values, VT = svd(snapshot_matrix, full_matrices=False)\n",
    "\n",
    "        # Truncate to first `num_modes` POD modes (can also be selected automatically or we give a value)\n",
    "        pod_basis = Phi[:, :num_modes]                       # Spatial POD modes (basis) left singular matrix\n",
    "        Sigma_r = np.diag(singular_values[:num_modes])       # Energy (singular values) \n",
    "        temporal_modes = VT[:num_modes, :]                   # Temporal/parametric info also right singular matrix\n",
    "\n",
    "        for velocity in velocities_to_plot:\n",
    "            if velocity not in velocity_to_index:\n",
    "                raise ValueError(f\"Velocity {velocity} not found in velocity_values.\")\n",
    "            v_idx = velocity_to_index[velocity]\n",
    "\n",
    "            # Compute modal coefficients α = Σ_r × VT_r[:, v_idx]\n",
    "            alpha = Sigma_r @ temporal_modes[:, v_idx]  # Shape: (num_modes,)\n",
    "            reduced_solution = pod_basis @ alpha        # Linear combination: Φ × α, here I want alpha to be trained\n",
    "\n",
    "            pod_solutions.setdefault(velocity, []).append(reduced_solution) # for time series data\n",
    "\n",
    "            # Save basis and coefficients from the first timestep only\n",
    "            if timestep == 0:\n",
    "                pod_bases[velocity] = pod_basis\n",
    "                pod_coefficients.setdefault(velocity, []).append(alpha)\n",
    "            else:\n",
    "                pod_coefficients[velocity].append(alpha)\n",
    "\n",
    "    # Convert all lists to arrays\n",
    "    for v in pod_solutions:\n",
    "        pod_solutions[v] = np.array(pod_solutions[v])\n",
    "        pod_coefficients[v] = np.array(pod_coefficients[v])\n",
    "\n",
    "    return pod_solutions, pod_bases, pod_coefficients\n",
    "\n",
    "# Save reconstructed solutions\n",
    "def save_pod_solutions(pod_solutions, output_folder='./'):\n",
    "    for velocity, solution in pod_solutions.items():\n",
    "        filepath = os.path.join(output_folder, f\"pod_solution_{velocity}.txt\")\n",
    "        np.savetxt(filepath, solution, fmt=\"%.6e\")\n",
    "    print(f\"POD solutions saved to folder: {output_folder}\")\n",
    "\n",
    "# Save solution plots\n",
    "def save_pod_plots(pod_solutions, time_values, output_folder='./'):\n",
    "    for velocity, solution in pod_solutions.items():\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(time_values, solution[:, 0], label=f'POD @ {velocity} m/s', linewidth=1.5)\n",
    "        plt.title(f'POD Reduced Solution at {velocity} m/s')\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"Displacement [cm]\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        file_path = os.path.join(output_folder, f\"pod_solution_{velocity}.png\")\n",
    "        plt.savefig(file_path)\n",
    "        plt.close()\n",
    "    print(f\"POD plots saved to folder: {output_folder}\")\n",
    "\n",
    "# Save POD basis and coefficients\n",
    "def save_pod_components(pod_bases, pod_coefficients, output_folder='./'):\n",
    "    for v, basis in pod_bases.items():\n",
    "        np.savetxt(os.path.join(output_folder, f\"pod_basis_{v}.txt\"), basis, fmt='%.6e')\n",
    "    for v, coeffs in pod_coefficients.items():\n",
    "        np.savetxt(os.path.join(output_folder, f\"pod_coeffs_{v}.txt\"), coeffs, fmt='%.6e')\n",
    "    print(\"POD basis functions and coefficients saved.\")\n",
    "\n",
    "# ------------------- PARAMETERS -------------------\n",
    "file_path = 'merged_rom.txt'#'reduced_order_method.txt'\n",
    "num_timesteps = 40001\n",
    "num_points = 9\n",
    "num_velocities = 201#101\n",
    "num_modes = 5\n",
    "\n",
    "#use all data to train not fixed ones \n",
    "velocities_to_plot = np.linspace(100, 500, 50)#num_velocities) #[100, 140, 180, 220, 260, 300, 340, 380, 420, 460, 500]\n",
    "velocity_values = np.linspace(100, 500, 50)#num_velocities)\n",
    "\n",
    "time_interval = 0.002\n",
    "time_values = np.linspace(0, (num_timesteps - 1) * time_interval, num_timesteps)\n",
    "\n",
    "# ------------------- EXECUTION -------------------\n",
    "data = load_and_reshape_data(file_path, num_timesteps, num_points, num_velocities)\n",
    "\n",
    "pod_solutions, pod_bases, pod_coefficients = compute_pod_solutions(\n",
    "    data, velocities_to_plot, velocity_values, num_modes\n",
    ")\n",
    "\n",
    "\n",
    "##save_pod_solutions(pod_solutions, output_folder)\n",
    "#save_pod_plots(pod_solutions, time_values, output_folder)\n",
    "#save_pod_components(pod_bases, pod_coefficients, output_folder)\n",
    "################Neural Network to get pod_coefficients\n",
    "\n",
    "#######################Here we train a NN ###########################\n",
    "#Step I\n",
    "# Prepare data for training\n",
    "X = []  # Input features (velocities)\n",
    "y = []  # Output targets (alpha coeffients)\n",
    "#augment same data taking so much memory\n",
    "for i in range(2):\n",
    "    for velocity, alphas in pod_coefficients.items():\n",
    "    #print(velocity, alphas.shape)\n",
    "        X.append(velocity)\n",
    "        y.append(alphas)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Dataset class in torch format\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class VelocityMatrixDataset(Dataset):\n",
    "    def __init__(self, velocities, matrices, exact_solutions=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            velocities (list or np.array): List of velocities\n",
    "            matrices (list of np.arrays): List of 40001x5 matrices\n",
    "            exact_solutions (list of np.arrays): \n",
    "                     List of exact solution matrices (optional)\n",
    "        \"\"\"\n",
    "        self.velocities = torch.FloatTensor(velocities)\n",
    "        self.matrices = torch.FloatTensor(np.array(matrices))  # Converts list to 3D tensor\n",
    "        self.exact_solutions = torch.FloatTensor(np.array(exact_solutions)) if exact_solutions is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.velocities)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.exact_solutions is not None:\n",
    "            return self.velocities[idx], self.matrices[idx], self.exact_solutions[idx]\n",
    "        return self.velocities[idx], self.matrices[idx]\n",
    "\n",
    "# NN  modify it as you like\n",
    "class ROMNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ROMNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU() #change activation fucntion\n",
    "\n",
    "    #I am simply trying a feed forward neural network\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Training parameters\n",
    "input_size = 1  # Since input is just velocity (scalar)\n",
    "hidden_size = 32 # modify it and see if it improves\n",
    "output_size = 40001 * 5  # Flattened output size (40001*5)\n",
    "batch_size = 2  # Small batch size as we dont have to much data \n",
    "num_epochs = 100  # Can be adjusted\n",
    "learning_rate = 0.001\n",
    "validation_split = 0.2  # 20% for validation\n",
    "\n",
    "# Assuming you have X (velocities) and y (matrices) loaded\n",
    "# X should be a list/array of 8 velocities\n",
    "# y should be a list of 8 matrices, each 40001x5\n",
    "\n",
    "# Create dataset \n",
    "full_dataset = VelocityMatrixDataset(X, y, exact_solutions=None)  # Add exact_solutions if available\n",
    "\n",
    "# Split into training and validation\n",
    "train_size = int((1 - validation_split) * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model, loss and optimizer\n",
    "model = ROMNet(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# For plotting\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "epochs = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    \n",
    "    # Training phase\n",
    "    for batch_velocities, batch_matrices in train_loader:\n",
    "        # Flatten matrices\n",
    "        batch_matrices_flat = batch_matrices.view(batch_matrices.size(0), -1)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_velocities.unsqueeze(1))\n",
    "        loss = criterion(outputs, batch_matrices_flat)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_train_loss += loss.item() * batch_velocities.size(0)\n",
    "    \n",
    "    # Calculate average training loss for the epoch\n",
    "    epoch_train_loss /= len(train_loader.dataset)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_velocities, batch_matrices in val_loader:\n",
    "            batch_matrices_flat = batch_matrices.view(batch_matrices.size(0), -1)\n",
    "            outputs = model(batch_velocities.unsqueeze(1))\n",
    "            loss = criterion(outputs, batch_matrices_flat)\n",
    "            epoch_val_loss += loss.item() * batch_velocities.size(0)\n",
    "    \n",
    "    epoch_val_loss /= len(val_loader.dataset)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    epochs.append(epoch + 1)\n",
    "    \n",
    "    # Print progress every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'Training Loss: {epoch_train_loss:.6f}, Validation Loss: {epoch_val_loss:.6f}')\n",
    "        print('-' * 50)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "line1, = ax.plot(epochs, train_losses, 'r-', label='Training Loss')\n",
    "line2, = ax.plot(epochs, val_losses, 'b-', label='Validation Loss')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training and Validation Loss')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Final evaluation function\n",
    "def evaluate_model(velocity, exact_matrix=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        velocity_tensor = torch.FloatTensor([velocity]).unsqueeze(1)\n",
    "        output_flat = model(velocity_tensor)\n",
    "        predicted_matrix = output_flat.view(40001, 5).numpy()\n",
    "\n",
    "        if exact_matrix is not None:\n",
    "            error = np.mean((predicted_matrix - exact_matrix) ** 2)\n",
    "            print(f'MSE Error: {error:.6f}')\n",
    "\n",
    "            # Plot comparison for first column (or any specific column)\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(predicted_matrix[:, 0], 'r-', label='Predicted')\n",
    "            plt.plot(exact_matrix[:, 0], 'b--', label='Exact')\n",
    "            plt.title(f'Comparison for velocity = {velocity}')\n",
    "            plt.xlabel('Index')\n",
    "            plt.ylabel('Value')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "    return predicted_matrix\n",
    "\n",
    "# Example usage:\n",
    "test_velocity = X[0]  # First velocity in your dataset\n",
    "exact_matrix = y[0]   # Corresponding exact matrix\n",
    "predicted_matrix = evaluate_model(test_velocity, exact_matrix)\n",
    "quit()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_velocities, batch_matrices in dataloader:\n",
    "        # Flatten the matrices for training\n",
    "        batch_matrices_flat = batch_matrices.view(batch_matrices.size(0), -1)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_velocities.unsqueeze(1))  # Add dimension for scalar input\n",
    "        loss = criterion(outputs, batch_matrices_flat)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Training finished!')\n",
    "\n",
    "# Function to predict matrix from velocity\n",
    "def predict_matrix(velocity):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        velocity_tensor = torch.FloatTensor([velocity]).unsqueeze(1)\n",
    "        output_flat = model(velocity_tensor)\n",
    "        # Reshape to 4001x5 matrix\n",
    "        predicted_matrix = output_flat.view(40001, 5)\n",
    "    return predicted_matrix.numpy()\n",
    "\n",
    "# Example usage:\n",
    "test_velocity = 100 # Your test velocity\n",
    "predicted_matrix = predict_matrix(test_velocity)\n",
    "print(predicted_matrix - pod_coefficients[100])  # Should be (4001, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
